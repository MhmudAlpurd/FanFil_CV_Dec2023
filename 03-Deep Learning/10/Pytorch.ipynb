{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088fd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd09a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_list = torch.tensor([1, 2, 3])\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb4865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_zeros = torch.zeros((3, 3))\n",
    "tensor_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d03501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ones = torch.ones((3,  3))\n",
    "tensor_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945ec267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9510, 0.0576, 0.5482],\n",
       "        [0.7920, 0.5869, 0.4054],\n",
       "        [0.8461, 0.7079, 0.2273]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_rand = torch.rand((3, 3))\n",
    "tensor_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e4a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1017, 0.3190, 0.8920],\n",
       "        [0.1326, 0.9551, 0.7525],\n",
       "        [0.6910, 0.5701, 0.8592]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float = torch.rand((3, 3),dtype=torch.float32)\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960cd392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "tensor([-3, -3, -3])\n",
      "tensor([ 4, 10, 18])\n",
      "tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "sum_a_b = a + b\n",
    "print(sum_a_b)\n",
    "\n",
    "sub_a_b = a - b\n",
    "print(sub_a_b)\n",
    "\n",
    "mul_a_b = a * b\n",
    "print(mul_a_b)\n",
    "\n",
    "div_a_b = a / b\n",
    "print(div_a_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef42a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3524, 0.2649, 0.3183],\n",
      "        [0.7021, 0.4613, 0.9264]])\n",
      "tensor([[0.3524, 0.7021],\n",
      "        [0.2649, 0.4613],\n",
      "        [0.3183, 0.9264]])\n"
     ]
    }
   ],
   "source": [
    "#transpose\n",
    "tensor_1 = torch.rand((2, 3))\n",
    "print(tensor_1)\n",
    "tensor_1_transpose = tensor_1.t()\n",
    "print(tensor_1_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e25fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#concatenation\n",
    "tensor_a = torch.tensor(([1, 2], [3, 4]))\n",
    "tensor_b = torch.tensor(([5, 6], [7, 8]))\n",
    "\n",
    "\n",
    "tensor_a_b_rows = torch.cat((tensor_a, tensor_b), dim=0) # rows\n",
    "tensor_a_b_cols = torch.cat((tensor_a, tensor_b), dim=1) # columns\n",
    "\n",
    "print(tensor_a_b_rows)\n",
    "print(tensor_a_b_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae3675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "tensor_a_gpu = tensor_a.to(device)\n",
    "tensor_b_gpu = tensor_b.to(device)\n",
    "\n",
    "result_on_gpu = tensor_a_gpu + tensor_b_gpu\n",
    "result_on_cpu = result_on_gpu.to('cpu')\n",
    "print(result_on_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5875493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#y = x^2\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "#dy/dx\n",
    "y.backward()\n",
    "print(x.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3210045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# z = x^2 + y^2\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "z = x**2 + y**2\n",
    "\n",
    "#dz/dx , dz/dy\n",
    "z.backward()\n",
    "\n",
    "print(x.grad.item())\n",
    "print(y.grad.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cdbc88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_derivative:  12.0\n",
      "second_derivative:  12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhmud/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  ../torch/csrc/autograd/engine.cpp:985.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "y = x**3\n",
    "\n",
    "\n",
    "y.backward(create_graph=True)\n",
    "print('first_derivative: ', x.grad.item())\n",
    "\n",
    "x.grad.zero_()\n",
    "\n",
    "y.backward(retain_graph=True)\n",
    "print('second_derivative: ', x.grad.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c7f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d875f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 5)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()       # Activation function\n",
    "        self.fc2 = nn.Linear(5, 1)  # Hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = SimpleNN()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a679b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1442]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample input data\n",
    "input_data = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "\n",
    "# Perform a forward pass\n",
    "output = model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8a2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 70.6954\n",
      "Epoch [20/100], Loss: 47.1968\n",
      "Epoch [30/100], Loss: 31.5090\n",
      "Epoch [40/100], Loss: 21.0357\n",
      "Epoch [50/100], Loss: 14.0436\n",
      "Epoch [60/100], Loss: 9.3756\n",
      "Epoch [70/100], Loss: 6.2592\n",
      "Epoch [80/100], Loss: 4.1787\n",
      "Epoch [90/100], Loss: 2.7897\n",
      "Epoch [100/100], Loss: 1.8625\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Sample target data\n",
    "target = torch.tensor([[10.0]])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef86762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex neural network\n",
    "class ComplexNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) #(input kernels, ouput kernels, kernel_size, padding)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.MaxPool2d(2)(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.LogSoftmax(dim=1)(x)\n",
    "\n",
    "# Create an instance of the network\n",
    "model = ComplexNN()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9adc03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 1\n",
    "\n",
    "# Import the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7784b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "batch_size = 64 # The number of samples per batch\n",
    "num_epochs = 10 # The number of times to iterate over the whole dataset\n",
    "learning_rate = 0.01 # The learning rate for the optimizer\n",
    "\n",
    "# Define the transformation to apply to the images\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.ToTensor(), # Convert the images to tensors\n",
    "\ttransforms.Normalize((0.1307,), (0.3081,)) # Normalize the pixel values with mean and std\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f405659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:39, 248537.21it/s]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 139026.42it/s]                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:05, 276183.63it/s]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 11970365.93it/s]                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset from the web\n",
    "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform) # The training set\n",
    "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform) # The test set\n",
    "\n",
    "# Create the data loaders for batching and shuffling the data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # The training loader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # The test loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e41f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\t# The network has two fully connected layers\n",
    "\t\tself.fc1 = nn.Linear(28*28, 512) # The first layer takes the flattened image as input and outputs 512 features\n",
    "\t\tself.fc2 = nn.Linear(512, 10) # The second layer takes the 512 features as input and outputs 10 classes\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# The forward pass of the network\n",
    "\t\tx = x.view(-1, 28*28) # Flatten the image into a vector\n",
    "\t\tx = F.relu(self.fc1(x)) # Apply the ReLU activation function to the first layer\n",
    "\t\tx = self.fc2(x) # Apply the second layer\n",
    "\t\treturn x # Return the output logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4942d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model and move it to the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Get the device\n",
    "model = Net().to(device) # Move the model to the device\n",
    "print(model) # Print the model summary\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss() # The cross entropy loss for multi-class classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate) # The stochastic gradient descent optimizer\n",
    "\n",
    "# Define a function to calculate the accuracy of the model\n",
    "def accuracy(outputs, labels):\n",
    "\t# The accuracy is the percentage of correct predictions\n",
    "\t_, preds = torch.max(outputs, 1) # Get the predicted classes from the output logits\n",
    "\treturn torch.sum(preds == labels).item() / len(labels) # Return the ratio of correct predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daa4658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "\t# Set the model to training mode\n",
    "\tmodel.train()\n",
    "\t# Initialize the running loss and accuracy\n",
    "\trunning_loss = 0.0\n",
    "\trunning_acc = 0.0\n",
    "\t# Loop over the batches of data\n",
    "\tfor i, (inputs, labels) in enumerate(train_loader):\n",
    "\t\t# Move the inputs and labels to the device\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabels = labels.to(device)\n",
    "\t\t# Zero the parameter gradients\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# Forward pass\n",
    "\t\toutputs = model(inputs) # Get the output logits from the model\n",
    "\t\tloss = criterion(outputs, labels) # Calculate the loss\n",
    "\t\t# Backward pass and optimize\n",
    "\t\tloss.backward() # Compute the gradients\n",
    "\t\toptimizer.step() # Update the parameters\n",
    "\t\t# Print the statistics\n",
    "\t\trunning_loss += loss.item() # Accumulate the loss\n",
    "\t\trunning_acc += accuracy(outputs, labels) # Accumulate the accuracy\n",
    "\t\tif (i + 1) % 200 == 0: # Print every 200 batches\n",
    "\t\t\tprint(f'Epoch {epoch}, Batch {i + 1}, Loss: {running_loss / 200:.4f}, Accuracy: {running_acc / 200:.4f}')\n",
    "\t\t\trunning_loss = 0.0\n",
    "\t\t\trunning_acc = 0.0\n",
    "\n",
    "# Define the test loop\n",
    "def test(model, device, test_loader, criterion):\n",
    "\t# Set the model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t# Initialize the loss and accuracy\n",
    "\ttest_loss = 0.0\n",
    "\ttest_acc = 0.0\n",
    "\t# Loop over the batches of data\n",
    "\twith torch.no_grad(): # No need to track the gradients\n",
    "\t\tfor inputs, labels in test_loader:\n",
    "\t\t\t# Move the inputs and labels to the device\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\t# Forward pass\n",
    "\t\t\toutputs = model(inputs) # Get the output logits from the model\n",
    "\t\t\tloss = criterion(outputs, labels) # Calculate the loss\n",
    "\t\t\t# Print the statistics\n",
    "\t\t\ttest_loss += loss.item() # Accumulate the loss\n",
    "\t\t\ttest_acc += accuracy(outputs, labels) # Accumulate the accuracy\n",
    "\t# Print the average loss and accuracy\n",
    "\tprint(f'Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_acc / len(test_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefe1875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 1.1024, Accuracy: 0.7609\n",
      "Epoch 1, Batch 400, Loss: 0.4941, Accuracy: 0.8737\n",
      "Epoch 1, Batch 600, Loss: 0.3922, Accuracy: 0.8938\n",
      "Epoch 1, Batch 800, Loss: 0.3661, Accuracy: 0.8996\n",
      "Test Loss: 0.3053, Test Accuracy: 0.9157\n",
      "Epoch 2, Batch 200, Loss: 0.3138, Accuracy: 0.9105\n",
      "Epoch 2, Batch 400, Loss: 0.2869, Accuracy: 0.9181\n",
      "Epoch 2, Batch 600, Loss: 0.2860, Accuracy: 0.9187\n",
      "Epoch 2, Batch 800, Loss: 0.2844, Accuracy: 0.9191\n",
      "Test Loss: 0.2455, Test Accuracy: 0.9320\n",
      "Epoch 3, Batch 200, Loss: 0.2415, Accuracy: 0.9310\n",
      "Epoch 3, Batch 400, Loss: 0.2480, Accuracy: 0.9284\n",
      "Epoch 3, Batch 600, Loss: 0.2381, Accuracy: 0.9313\n",
      "Epoch 3, Batch 800, Loss: 0.2351, Accuracy: 0.9345\n",
      "Test Loss: 0.2112, Test Accuracy: 0.9405\n",
      "Epoch 4, Batch 200, Loss: 0.2036, Accuracy: 0.9423\n",
      "Epoch 4, Batch 400, Loss: 0.2227, Accuracy: 0.9370\n",
      "Epoch 4, Batch 600, Loss: 0.2003, Accuracy: 0.9439\n",
      "Epoch 4, Batch 800, Loss: 0.1995, Accuracy: 0.9436\n",
      "Test Loss: 0.1847, Test Accuracy: 0.9483\n",
      "Epoch 5, Batch 200, Loss: 0.1942, Accuracy: 0.9450\n",
      "Epoch 5, Batch 400, Loss: 0.1827, Accuracy: 0.9466\n",
      "Epoch 5, Batch 600, Loss: 0.1769, Accuracy: 0.9518\n",
      "Epoch 5, Batch 800, Loss: 0.1739, Accuracy: 0.9502\n",
      "Test Loss: 0.1652, Test Accuracy: 0.9529\n",
      "Epoch 6, Batch 200, Loss: 0.1635, Accuracy: 0.9537\n",
      "Epoch 6, Batch 400, Loss: 0.1685, Accuracy: 0.9515\n",
      "Epoch 6, Batch 600, Loss: 0.1598, Accuracy: 0.9576\n",
      "Epoch 6, Batch 800, Loss: 0.1538, Accuracy: 0.9551\n",
      "Test Loss: 0.1519, Test Accuracy: 0.9554\n",
      "Epoch 7, Batch 200, Loss: 0.1500, Accuracy: 0.9577\n",
      "Epoch 7, Batch 400, Loss: 0.1484, Accuracy: 0.9595\n",
      "Epoch 7, Batch 600, Loss: 0.1359, Accuracy: 0.9625\n",
      "Epoch 7, Batch 800, Loss: 0.1334, Accuracy: 0.9637\n",
      "Test Loss: 0.1393, Test Accuracy: 0.9602\n",
      "Epoch 8, Batch 200, Loss: 0.1326, Accuracy: 0.9644\n",
      "Epoch 8, Batch 400, Loss: 0.1313, Accuracy: 0.9646\n",
      "Epoch 8, Batch 600, Loss: 0.1352, Accuracy: 0.9616\n",
      "Epoch 8, Batch 800, Loss: 0.1254, Accuracy: 0.9651\n",
      "Test Loss: 0.1281, Test Accuracy: 0.9635\n",
      "Epoch 9, Batch 200, Loss: 0.1201, Accuracy: 0.9676\n",
      "Epoch 9, Batch 400, Loss: 0.1211, Accuracy: 0.9661\n",
      "Epoch 9, Batch 600, Loss: 0.1181, Accuracy: 0.9677\n",
      "Epoch 9, Batch 800, Loss: 0.1181, Accuracy: 0.9684\n",
      "Test Loss: 0.1194, Test Accuracy: 0.9649\n",
      "Epoch 10, Batch 200, Loss: 0.1083, Accuracy: 0.9708\n",
      "Epoch 10, Batch 400, Loss: 0.1083, Accuracy: 0.9698\n",
      "Epoch 10, Batch 600, Loss: 0.1122, Accuracy: 0.9684\n",
      "Epoch 10, Batch 800, Loss: 0.1144, Accuracy: 0.9698\n",
      "Test Loss: 0.1125, Test Accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAI4CAYAAABeEiKtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6bklEQVR4nO3deZhUxb3/8c+XRUBUwiougAHEBFEBUdG4YCSCCy5RIlc0oMZoIsZERYliJAjxBnPluoHRq6J4w0VxDSLihjuJcAV3/YFhgIsIhEXZwjL1++OcSdo5dbC7p3umeub9ep55mPl0nTrVPcXMt2tOdZtzTgAAACGoV9MDAAAAqEBhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAghFsYWJms83sJ9V9bEjMzJlZ5/jzu83shjz72WBmHQs7OhQKc525Xlcw15nr2Sh6YWJmi82sb7HPk694YmzI+PiHmX2V5bF9zKw8Pu4rM/vEzC4oxjidc5c6527KYkyJ/7zOud2cc58VY1yVzr2h0scOM7uj2OcNRQnM9SFmNs/MvjSzZWY2zswaZHksc/1f521kZveZWVn8WLxjZicV85yhKYG53s3MnjOz1WaW04t1MdcT5x5mZnPj342Tin0+KeAVk+oST4zdKj4kTZH0aA5dLI+P20PStZLuNbOulRtl+wuglFV6HPeUtFm5PZYorl0l/VJSK0lHSDpB0tU5HM9cjzSQtFTScZKaSbpB0iNmtl9NDgpfs03SI5IuyvN45vq/LJc0RtL91XXCGitMzKy5mU03s1Vmtjb+fN9KzTqZ2V/NbL2ZPWVmLTKO721mb5rZOjNbYGZ9CjCmppLOkvRgrse6yJOS1krqamZDzewNMxtvZmskjYqfaf3BzJaY2Rfxak2TjPMPN7PPzWy5mV1YaWyTzGxMxtenm9n8+NnvIjPrb2ZjJR0j6c642r8zbpu5dNjMzB6KH/cyMxtpZvXi24aa2evxGNea2d+q8EzwbEkrJb2W5/G1Rihz3Tk30Tn3mnNuq3Pu/yT9t6Tv5dFPnZ7rzrmNzrlRzrnFzrly59x0SX+TdGiuj2VtE9Bc/8Q5d5+kD/K/N8z1+DF4PH4M/p7v45irmlwxqSfpAUkdJLVX9Oz6zkptfizpQkl7S9ou6XZJMrN9JD2jqIproehZ32Nm1rryScysfTzJ22cxprMkrZL0aq53xszqmdmZkr4l6b04PkLSZ5LaSBor6feSukjqLqmzpH0k/SY+vn98P34gaX9JqcukZna4pIckDY/Pd6ykxc656xUVAsPilYthnsPvUPQsr6OiZ3w/lpS5THmEpE8UPaseJ+k+M7P4vCPMbHqWD8kQSQ853vNACnOuS9G8yfkHN3M9McY94/tapV+CtUSocz0vzPUa4pwr6oekxZL6ZtGuu6S1GV/PlvTvGV93lbRVUn1FS2uTKx3/nKQhGcf+JI+xvihpVA7t+0gql7RO0hpJ8yUNim8bKmlJRluTtFFSp4zsSEl/iz+/v9L97SLJSeocfz1J0pj48z9KGp8ypsR9r+gnfuz+Ialrxm2XSJqdMeaFGbftGh/bNsfHsb2kHZK+Xez5FdJHic31CyQtk9Qqy/bMdf8YGkp6QdIfa3r+VedHqcz1eC64HI9hrvvHMEbSpOqYXzX29zEz21XSeEn9JTWP493NrL5zbkf89dKMQ8oU/RBopagaH2hmAzJubyjp5SqMp52iSvPiHA9d7pyrvFRZIXP8rRVNiHlxoSpFk7p+/PnekuZltC/byTnbSZqR4zil6LHbpVLfZYoq/AorKj5xzm2Kx7pbjuf5saTXnXN/y2OMtU6Ac/0MSf+u6BfL6hwOZa5niJfKJyv6xep7FlvnhDbXq4C5XoNq8sKdqyQdIOkI59wKM+su6R1F39QK7TI+b6/ogqbViibGZOdcrkXEzvxY0puusFc5Z/4ZY7WiZc0DXfT3/co+V/L+plkqqVMW56xstaLHsIOkDzPO4xtPVfxY0S8+RIKZ6/HS8r2STnHOvfdN7XNQp+Z6vAx+n6KLvE92zm0rRL+1QDBzvYjq1FyvCdV1jUlDM2uc8dFA0u6KvqHr4oufbvQcd56ZdY2r8NGSpsVV98OSBphZPzOrH/fZx3ORVS5+rGhZ7Wvii5MSea6cc+WKfiGMN7M2cd/7mFm/uMkjkoZm3F/f41HhPkkXmNkJ8d9A9zGz78S3faHo74y+MeyIzzPWzHY3sw6SrlT0eBaEmR2lqFKvq7txgp3rZvZ9RRe8nuWc+6vnduZ69iZK+q6kAc65zQXqs9SEPNfNzBorWklQ3FejjNuZ61kyswbxY1lfUsX3paiLGtVVmMxQNFkrPkZJ+k9JTRRVe3MkzfQcN1lRsbBCUmNJv5Ak59xSSadLuk7RxapLFV0wlLg/8UVSG3Z2kZSZHSlpX/l/mbaT9MY33sPsXCtpoaQ5Zvalor9NHyBJzrlnFT0mL8VtXkrrJP6lcoGiJdP1kl5RVC1L0m2Szrbo6uvbPYdfruhvop9Jel3Sn5TlNjAzu87Mnv2GZkMkPe6cy+q1YGqhkOf6DYoukJth/3qtmczvJ3M9trO5Hv/gv0TR9RMrMh7Lwdn0XYuEPNc7xGOquCB5s6KLPysw12NZ/FwfqejxGyHpvPjzkdn0nS+LL2qBh5ntImmBpINZqkVtxlxHXcFcDx+FCQAACEadf+VXAAAQDgoTAAAQDAoTAAAQjJ1u+bEc35URKAbnnH1zq6phriME1THXJeY7wpA231kxAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwWhQ0wMAUH2uvvpqb96kSZNEdvDBB3vbnn322Tmdc+LEid78rbfeSmSTJ0/OqW8AtQ8rJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBjmnEu/0Sz9RqCaOOes2OeobXN96tSp3jzXHTXFtGjRokTWt29fb9slS5YUezhBqI65LtW++V4KunTpksg+/vhjb9srrrjCm99xxx0FHVNNS5vvrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBg8F45QAkr5u6btB0Dzz33nDfv2LGjNx8wYIA379SpUyIbPHiwt+3NN9/szYFS0aNHj0RWXl7ubbts2bJiDydorJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgsCsHKAG9evXy5meeeWZO/XzwwQfe/LTTTktkq1ev9rbdsGGDN99ll128+Zw5c7z5IYcckshatmzpbQuUuu7duyeyjRs3ets+8cQTRR5N2FgxAQAAwaAwAQAAwaAwAQAAwaAwAQAAwSiZi199L7F98cUXe9suX77cm2/ZssWb//d//7c3X7FiRSJbuHBh2hCBotlrr728uZl587SLXPv16+fNP//88/wGluGqq67y5l27ds26j2eeeabK4wBqUrdu3bz5sGHDEtnkyZOLPZySxIoJAAAIBoUJAAAIBoUJAAAIBoUJAAAIBoUJAAAIRsnsyhk3blwi22+//QrS9yWXXOLNv/rqq0SWttuhFCxbtiyR+R5XSZo7d26xh4Mc/PnPf/bmnTt39ua+uStJa9asKdiYKhs0aJA3b9iwYdHOCYTmO9/5jjdv2rRpIps6dWqxh1OSWDEBAADBoDABAADBoDABAADBoDABAADBoDABAADBKJldOb73xTn44IO9bT/66CNv/t3vfteb9+zZ05v36dMnkfXu3dvbdunSpd68Xbt23jwX27dv9+arVq3y5mnvq+KzZMkSb86unNJQVlZW7eccPny4N+/SpUtO/fzlL3/JKgNKyTXXXOPNff9X+Tnrx4oJAAAIBoUJAAAIBoUJAAAIBoUJAAAIBoUJAAAIhjnn0m80S7+xDmjevHki6969u7ftvHnzvPlhhx1W5XFs2bLFm3/66afePG1XUosWLRLZZZdd5m07ceLELEdXfM45K/Y56vpc9zn11FO9+aOPPurNd9llF2++cuVKb+57b51XXnkly9HVTtUx1yXmeyGkvVfbZ5995s19P6/T3lenrkib76yYAACAYFCYAACAYFCYAACAYFCYAACAYFCYAACAYJTMe+XUhLVr1yayl19+Oac+XnzxxUINJ+Gss87y5r7dRJL03nvvJbKpU6cWdEyoPXr16uXN03bfpEmbY3V9Bw5K23HHHZdT+7T3NkMSKyYAACAYFCYAACAYFCYAACAYFCYAACAYXPxaAtq0aePNJ0yY4M3r1fPXm6NHj05ka9asyX9gqDWefPLJRHbiiSfm1MdDDz3kzUeOHJnPkICgHXTQQTm1HzduXJFGUvuwYgIAAIJBYQIAAIJBYQIAAIJBYQIAAIJBYQIAAILBrpwScNlll3nz1q1be3PfS+lL0ieffFKwMaE07bXXXt78qKOOSmSNGjXytl29erU3HzNmjDffsGFDlqMDwtO7d29vfsEFF3jzd955x5s///zzBRtTbceKCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAa7cgLzve99L5GNGDEipz7OOOMMb/7+++/nMyTUIo899pg3b9myZdZ9PPzww9580aJFeY0JCFnfvn29eYsWLbz5zJkzvfmWLVsKNqbajhUTAAAQDAoTAAAQDAoTAAAQDAoTAAAQDAoTAAAQDHblBObkk09OZA0bNvS2ffHFF735W2+9VdAxofScdtpp3rxnz55Z9zF79mxvfuONN+YzJKAkHXLIId7cOefNp02bVszh1AmsmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGCwK6eGNGnSxJv3798/kW3dutXbNm13xLZt2/IfGEpK2nvcXHfddd48bYeXz/z58735hg0bsu4DKBVt27b15sccc4w3/+STT7z5E088UbAx1VWsmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBw8WsNGT58uDfv0aNHIps5c6a37ZtvvlnQMaH0XHXVVd78sMMOy6mfJ598MpHx0vOoS4YOHerN27Rp482fffbZIo6mbmPFBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABINdOUV2yimnePMbbrjBm3/55ZeJbPTo0QUdE2qPK6+8siD9DBs2LJHx0vOoSzp06JBT+7Vr1xZpJGDFBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABINdOQXSsmVLb3777bd78/r163vzGTNmJLI5c+bkPzAgCy1atEhk27ZtK+o5169fn/U5GzZs6M2bNWuW9fm+9a1vefNC7WzasWNHIrv22mu9bTdt2lSQc6JwTj311Jza//nPfy7SSMCKCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAa7cnKUtptm5syZ3vzb3/62N1+0aJE3T3sPHaCY3n333Wo/56OPPprIPv/8c2/bPffc05ufc845BR1Toa1YscKbjx07tppHgkxHH310Imvbtm0NjAQ+rJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgcPFrjjp16uTNDz300Jz6SXsZ7LSLYgEf31sYSNLpp59ezSPJ3cCBA4vW9/bt2xNZeXl5Tn08/fTT3nzu3LlZ9/Haa6/ldE5UjzPPPDORpW1seOedd7z5q6++WtAx4V9YMQEAAMGgMAEAAMGgMAEAAMGgMAEAAMGgMAEAAMFgV85OdOjQIZHNmjUrpz6GDx/uzadPn57XmIBMP/zhD735Nddc480bNmxY5XMeeOCB3rwQLw9///33e/PFixfn1M9jjz2WyD7++ON8hoQStuuuu3rzk08+Oes+pk2b5s137NiR15jwzVgxAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwTDnXPqNZuk31gFjx45NZL/+9a9z6uPwww/35rm830Zd55yzYp+jrs91hKE65rpUd+Z72i60V155JZGtXLnS2/bcc8/15ps2bcp/YJCUPt9ZMQEAAMGgMAEAAMGgMAEAAMGgMAEAAMGgMAEAAMHgvXIkHX300d788ssvr+aRAAAKZdu2bd78qKOOquaRIBesmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGCwK0fSMccc48132223rPtYtGiRN9+wYUNeYwIAoC5ixQQAAASDwgQAAASDwgQAAASDwgQAAASDi19ztGDBAm9+wgknePM1a9YUczgAANQqrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgmHMu/Uaz9BuBauKcs2Kfg7mOEFTHXJeY7whD2nxnxQQAAASDwgQAAASDwgQAAASDwgQAAASDwgQAAARjp7tyAAAAqhMrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBjBFiZmNtvMflLdx4bEzJyZdY4/v9vMbsiznw1m1rGwo0OhMNeZ63UFc525no2iFyZmttjM+hb7PFVhZr8ysxVmtt7M7jezRlke18fMyuMJ8pWZfWJmFxRjjM65S51zN2UxpsR/Xufcbs65z4oxrkrnbmFmT5jZRjMrM7Nzi33OkJTCXK9gZi/FPyAbZNmeue4fw/5mtsXMHq6uc4Yg9LluZt3M7DkzW21mOb1TLXM9ce5hZjbXzP5hZpOKfT4p4BWT6mJm/SSNkHSCpP0kdZT02xy6WO6c203SHpKulXSvmXX1nCerXwAl7i5JWyXtKWmwpIlmdmDNDgmVmdlgSfnMR+Z60l2S3q7pQSBhm6RHJF2U5/HM9X9ZLmmMpPur64Q1VpiYWXMzm25mq8xsbfz5vpWadTKzv8YrGU+ZWYuM43ub2Ztmts7MFphZnzyHMkTSfc65D5xzayXdJGlorp24yJOS1krqamZDzewNMxtvZmskjTKzRmb2BzNbYmZfxMt4TTLu03Az+9zMlpvZhZn9m9kkMxuT8fXpZjbfzL40s0Vm1t/Mxko6RtKdcbV/Z9w2c+mwmZk9FD/uZWY20szqxbcNNbPX4zGuNbO/mdlJ2dx/M2sq6SxJNzjnNjjnXpf0tKTzc30sa5uA5rrMrJmkGyVdk28fdX2uZ4xrkKR1kl7M42GslUKZ6865T5xz90n6IP97w1yPH4PH48fg7/k+jrmqyRWTepIekNRBUntJmyXdWanNjyVdKGlvSdsl3S5JZraPpGcUVXEtJF0t6TEza135JGbWPp7k7VPGcaCkBRlfL5C0p5m1zOXOmFk9MztT0rckvRfHR0j6TFIbSWMl/V5SF0ndJXWWtI+k38TH94/vxw8k7S8pdZnUzA6X9JCk4fH5jpW02Dl3vaTXJA2Ll/mGeQ6/Q1IzRStDxyl6jDOXKY+Q9ImkVpLGSbrPzCw+7wgzm54yrC6SdjjnPs3IFih6fOu6UOa6JP1O0kRJK/K9M8x1ycz2kDRa0lVpbeqokOZ6lTHXa4hzrqgfkhZL6ptFu+6S1mZ8PVvSv2d83VXRnwnqK1pam1zp+OckDck49idZjm+RpP4ZXzeU5CTtl8WxfSSVK3rWtEbSfEmD4tuGSlqS0dYkbZTUKSM7UtLf4s/vr3R/u8Tj6Bx/PUnSmPjzP0oanzKmxH2v6Cd+7P4hqWvGbZdImp0x5oUZt+0aH9s2i8fiGEkrKmUXV/RdFz5KYK73iudoA0V/tnSSGmR5LHP96+e5TdK18eejJD1c0/OvOj9Cn+sZx3dWtPCRyzHMdf8YxkiaVB3zq8b+PmZmu0oaL6m/pOZxvLuZ1XfO7Yi/XppxSJmioqGVomp8oJkNyLi9oaSX8xjKBkV/R6xQ8flXWR6/3DlXeamyQub4WyuaEPPiQlWKJnX9+PO9Jc3LaF+2k3O2kzQjy/FlaiVpl0p9lymq8Cv885m0c25TPNbdsui78uOo+OtsH8daK4S5Hi/rTpB0hXNue8YczAVzXZKZdVf0zLdHHuOq1UKY6wXCXK9BNXnhzlWSDpB0hHNuRfyf/R1F39QK7TI+b6/ogqbViibGZOfcxQUYxweSDlF0oZTiz79wzhXi72mZV4OvVrSseaBz7v88bT9X8v6mWSqpUxbnrGy1osewg6QPM87jG0+uPpXUwMz2d879vzg7RFX8G28tEcJc30PRisnU+IdSxQ/OZWY20Dn3WhX7r0tzvY+iFaclGT/g65tZV+dczwL0X8pCmOvFVpfmeo2ormtMGppZ44yPBpJ2V/QNXRdf/HSj57jzzKxrXIWPljQtrrofljTAzPqZWf24zz6WvMgqGw9Juig+T3NJIxUtr0n658VJk1KOzZpzrlzSvZLGm1mbuO99LNoVJEWF0dCM++t7PCrcJ+kCMzsh/hvoPmb2nfi2LxT9ndE3hh3xecaa2e5m1kHSlYoez6rev42SHpc02syamtn3JJ0uaXJV+y4xoc719YqevXWPP06O80Ml/UVirufgHkW/QLrHH3crujaiX/ohtVKoc10WaaxoJUFxX40ybmeuZ8nMGsSPZX1FBXjF97poqqswmaFoslZ8jJL0n5KaKKr25kia6TlusqIiYYWkxpJ+IUnOuaWKfuldJ2mVokpzuDz3x6KLpDZYykVSzrmZii4GelnR8leZvj552kl6I/u7ulPXSlooaY6ZfSnpBUXPLuSce1bRY/JS3OaltE6cc39VdGHTeEW/cF5RVC1L0d++z7bo6uvbPYdfruhvop9Jel3Sn5TlNjAzu87Mnt1Jk58r+p6ulDRF0s+cc3VtxSTIue4iKyo+4r6kaHVwa/w5cz22s7nunNtU6bHcIGmLc26Vr30tFuRcj3WIx1Tx82ezoos/KzDXY1n8XB+p6PEbIem8+POR2fSdL4svaoGHme2iaGfJwc65bTU9HqBYmOuoK5jr4aMwAQAAwajzr/wKAADCQWECAACCQWECAACCsdMtP5bjuzICxeCcy+vVwHLBXEcIqmOuS8x3hCFtvrNiAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgtGgpgdQapo2berNb7nlFm9+ySWXePN58+Z584EDByaysrKyLEcHAEBpY8UEAAAEg8IEAAAEg8IEAAAEg8IEAAAEg8IEAAAEw5xz6Teapd9YR3Xu3Nmbf/TRRzn1U6+evyb8xS9+kcjuuuuunPqubZxzVuxz1JW53rNnT2/++OOPJ7L99tuvyKOpuhNPPNGb+/4/Ll26tNjDqbLqmOtS3ZnvIRkwYEAie/rpp71thw0b5s3vvvtub75jx478B1aD0uY7KyYAACAYFCYAACAYFCYAACAYFCYAACAYFCYAACAYvFfOTrRu3TqRPfjggzUwEqAw+vXr580bNWpUzSMpDN9OB0m68MILE9mgQYOKPRxALVu29OYTJkzIuo8777zTm99///3efPPmzVn3XQpYMQEAAMGgMAEAAMGgMAEAAMGgMAEAAMHg4lf5XwZeks4444xEdvjhhxd1LMcee2wiS3v5+gULFnjzV199taBjQulp0MD/X/vkk0+u5pEU17x587z5lVdemciaNm3qbbtx48aCjgl1m+9nuCTtu+++WfcxZcoUb75ly5a8xlRqWDEBAADBoDABAADBoDABAADBoDABAADBoDABAADBYFeOpPHjx3vz8vLyah6J9MMf/jCrTJLKysq8+TnnnOPN03YwoPY5/vjjvfmRRx7pzceNG1fM4RRN8+bNvXnXrl0T2a677upty64c5CPtbRyuv/76Kvc9efJkb+6cq3LfpYAVEwAAEAwKEwAAEAwKEwAAEAwKEwAAEAwKEwAAEAzb2VW+ZlarLgGeMWOGNz/ppJO8eTF35fz973/35hs2bEhkHTp0KMg569evX5B+qptzzop9jlKd6926dfPms2fP9uZp8+7QQw9NZL65GJq0+3n00Ucnsr322svbdtWqVYUcUpVUx1yXSne+h6RXr17e/O233866j+3bt3vzhg0b5jWmUpM231kxAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaiV75Vz3HHHefMDDjjAm6ftvinErpy7777bm8+aNcubr1+/PpF9//vf97bN9T0ZfvaznyWyiRMn5tQHwjJy5Ehv3rRpU2/ev39/bx76DpwWLVp487T/6zXxPleoW84666wq95H2e6CuY8UEAAAEg8IEAAAEg8IEAAAEg8IEAAAEg8IEAAAEo6R35ey3337e/H/+53+8eatWrap8zrKyMm/+2GOPefPf/va33nzTpk1VPudPf/pTb966dWtvPm7cuETWuHFjb9s777zTm2/bts2bo7jOPvtsb37yySd784ULF3rzuXPnFmxM1SltB1ra7hvfe+isW7eugCNCXXfsscfm1H7r1q2JLNedlXUFKyYAACAYFCYAACAYFCYAACAYFCYAACAYJX3xa4MG/uEX4iJXSXrllVcS2aBBg7xtV69eXZBz+qRd/HrzzTd781tvvdWb77rrronMd0GsJD399NPefNGiRd4cxTVw4EBv7vueStKECROKOZyiSbugffDgwd58x44d3nzMmDGJjAu3kY+jjjoqpzzNxo0bE9n8+fPzGVKtx4oJAAAIBoUJAAAIBoUJAAAIBoUJAAAIBoUJAAAIRknvyimUtJfpvvDCCxNZMXff5Cpt50zaDobDDjusmMNBgTRr1iyR9e7dO6c+Jk6cWKjhVKu0t1lI22n30UcfefOXX365YGNC3Vaon5ul+n+yJrBiAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAglErd+XUq5dbvXXEEUcUaSTFZWbePO3+5/K4jBo1ypuff/75WfeB/DRq1CiR7bPPPt62U6ZMKfZwqlWnTp1yav/+++8XaSRApFevXjm1X7dunTdnV072WDEBAADBoDABAADBoDABAADBoDABAADBoDABAADBKOldOZdeeqk3Ly8vr+aR1IwBAwZ48x49enhz3+OS9lil7cpB8X311VeJbP78+d62Bx98sDdv0aKFN1+zZk3e4yq0Nm3aJLKzzz47pz5ef/31Qg0HddzRRx/tzc8999yc+lm/fr03X7ZsWc5jqqtYMQEAAMGgMAEAAMGgMAEAAMGgMAEAAMGgMAEAAMEo6V05abtSSlnr1q0TWdeuXb1tr7vuuiqfb9WqVd5827ZtVe4b+dm8eXMiW7RokbftWWed5c2feeYZb37rrbfmP7Bv0K1bN2/esWNHb77ffvslMudcTuesKzvwUHwtW7b05rm+99rzzz9fiOHUaayYAACAYFCYAACAYFCYAACAYFCYAACAYJT0xa+10fXXX5/ILrvssoL0vXjx4kQ2ZMgQb9slS5YU5JwojBtvvNGbm5k3P+WUU7z5lClTCjamylavXu3N0y5obdWqVZXPOWnSpCr3AUi5vx3CunXrvPkf//jHAoymbmPFBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABMN29hLQZpbb60NXs08++cSbp70EdpqGDRsWYjg5mTFjhjc/4IADEln79u0Lcs6ZM2cmslJ4WX/nnH/rSQGFPtdz1b17d2/euXPnop1z2rRpObV/8MEHE9ngwYNz6qNBg9q1sbA65rpU++Z7rvbdd99EVlZW5m2b9pL077//vjc/6KCD8h9YHZM231kxAQAAwaAwAQAAwaAwAQAAwaAwAQAAwaAwAQAAwSjpS9rT3ick7SrqNCeddFLWbe+55x5vvvfee+d0zrQxlpeX59RPLkphBw4KY/78+TnlNeGzzz6rch/dunXz5mk7JgBJOuqooxJZrr83nnzyyQKNBpWxYgIAAIJBYQIAAIJBYQIAAIJBYQIAAIJBYQIAAIJR0rtyJk6c6M3HjRuXUz/Tp0/35rnskCnUbppC9HP33XcXYCRAcfl21aXttEvD7hvko2XLllm3Xb16tTe/7bbbCjUcVMKKCQAACAaFCQAACAaFCQAACAaFCQAACEZJX/z6+OOPe/Phw4d789atWxdzOAWxatWqRPbRRx952/70pz/15p9//nlBxwQUg3MuqwwotH79+mXddsmSJd58/fr1hRoOKmHFBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABKOkd+WUlZV580GDBnnzM844w5tfccUVhRpSlY0dOzaR3XXXXTUwEqC4GjdunHXbzZs3F3EkqK0aNmzozTt16pR1H1u2bPHm27Zty2tM+GasmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGCU9K6cNK+++mpO+axZs7y5771oBgwY4G379NNPe/N77rnHm5uZN//www+9OVDbXHDBBYls3bp13rY33XRTkUeD2qi8vNybz507N5F169bN23bhwoUFHRO+GSsmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGLVyV06uZs6cmVMOoOrefvvtRHbrrbd627788svFHg5qoR07dnjz66+/PpE557xt582bV9Ax4ZuxYgIAAIJBYQIAAIJBYQIAAIJBYQIAAIJBYQIAAIJhaVciS5KZpd8IVBPnnP+NhQqIuY4QVMdcl5jvCEPafGfFBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABIPCBAAABMOcczU9BgAAAEmsmAAAgIBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGAEW5iY2Wwz+0l1HxsSM3Nm1jn+/G4zuyHPfjaYWcfCjg6FwlxnrtcVzHXmejaKXpiY2WIz61vs8xSCmb0UT5oGWbbvY2bl8QT5ysw+MbMLijE259ylzrmbshhT4j+vc24359xnxRhXyhj2N7MtZvZwdZ0zBKHPdTNrZGbjzWy5ma01swlm1jDLY5nrXz/3d+OfF+vNbKGZnVnsc4akBOb6UDPbEc/Xio8+WR7LXE+ef5CZfWRmG81skZkdU8zzBbtiUt3MbLCkrAqSSpY753aTtIekayXda2ZdPf3n03epukvS2zU9CCSMkNRLUjdJXST1lDQyh+OZ6/rn/XtK0nRJLST9VNLDZtalRgeGyt6Kf3lXfMzO4VjmeszMfiDp95IukLS7pGMlFbUgqrHCxMyam9l0M1sVP3ubbmb7VmrWycz+Gj8recrMWmQc39vM3jSzdWa2INtqOGUszSTdKOmafPtwkSclrZXUNa7Y34ifoa6RNCp+xvoHM1tiZl/Ey3hNMsYx3Mw+j5/RXlhpjJPMbEzG16eb2Xwz+zKuYPub2VhJx0i6M67274zbZi4dNjOzh+LHvczMRppZvfi2oWb2ejzGtWb2NzM7KZfHwcwGSVon6cU8HsZaKaC5PkDS7c65Nc65VZJul3ThNxyTwFzXdyTtLWm8c26Hc+4lSW9IOj/Xx7K2CWiuFwRzXZL0W0mjnXNznHPlzrn/c879X36PaHZqcsWknqQHJHWQ1F7SZkl3VmrzY0U/OPeWtF3RD1KZ2T6SnpE0RtEzlqslPWZmrSufxMzax5O8/U7G8jtJEyWtyPfOmFk9i5ZzvyXpvTg+QlFl2UbSWEVVZxdJ3SV1lrSPpN/Ex/eP78cPJO0vKXWZ1MwOl/SQpOHx+Y6VtNg5d72k1yQNi58hDPMcfoekZpI6SjpO0WOcuUx5hKRPJLWSNE7SfWZm8XlHmNn0nYxrD0mjJV2V1qaOCmWuW/yR+fW+FhXmWWOuf+0xzMy6pd2POiSUuS5JPcxstZl9amY3WB6rG3V9rptZfUWrrK0t+pPlMjO7M7PwKgrnXFE/JC2W1DeLdt0lrc34erakf8/4uqukrZLqK1pam1zp+OckDck49idZjq+XpPmK/oyznyQnqUGWx/aRVK5ohWBN3M+g+LahkpZktDVJGyV1ysiOlPS3+PP7K93fLvFYOsdfT5I0Jv78j4qerfnGlLjvFf3Ej90/JHXNuO0SSbMzxrww47Zd42PbZvl43Cbp2vjzUZIeLvb8CumjBOb6GEXP7FtLaivpL/H3d68sjmWu/6ttQ0W/mK6JPz8x/n49V9NzkLn+z+M6Svq2okLpIEkfSvp1lscy1//Vdu+47VxJeykqbN6QNLaY86vG/j5mZrtKGi+pv6Tmcby7mdV3zu2Iv16acUiZoh8CrRRV4wPNbEDG7Q0lvZzjGOpJmiDpCufc9riAzNVy51zlpcoKmeNvrWhCzMs4jymaVFI0AeZltC/byTnbSZqR+1DVStIulfouU1ThV/jnqpFzblM81t2+qWMz667o2UCPPMZVq4Uw12NjFT0Tm6/oB9m9ir5fK7M8nrketd1mZmcoepZ6raIf2o8oekzrtFDmuvv6RaHvmdloRSsRN2fZBXM9sjn+9w7n3OeSZGa3Kro27fo8xpqVmrxw5ypJB0g6wjm3Iv7F9o6+vkzaLuPz9pK2SVqtaGJMds5dXMUx7KFoxWRq/I2qmEzLzGygc+61KvbvMj5freibfKDz/33ucyXvb5qlkjplcc7KVit6DDsoegZRcZ5C/L2wj6IVpyUZk76+mXV1zvUsQP+lLIS5LufcZknD4g+Z2U8lzcv4hVGl7jM+r+1zXc65dxUtmUuSzOxNSQ8Wou8SF8Rc93Dy/wku374q1Oq57pxba2bLvuH8BVdd15g0NLPGGR8NFF3du1nSOosufrrRc9x5ZtY1rsJHS5oW/xB9WNIAM+tnZvXjPvtY8iKrb7JeUUXbPf44Oc4PVbTMXXFx0qQc+01wzpUreoY63szaxH3vY2b94iaPSBqacX99j0eF+yRdYGYnxH8D3cfMvhPf9oWiZUzfGHbE5xlrZrubWQdJVyp6PKvqHkX/qbrHH3cr+ntxv/RDaqVQ53rFfNvbIr0l3ZA5FuZ69szs4Ph7sauZXa1omXtSIfouISHP9ZPMbM/48+8omutPZdzOXM/eA5IuN7M2ZtZc0i8V7UgrmuoqTGYomqwVH6Mk/aekJoqqvTmSZnqOm6zoP/sKSY0l/UKSnHNLJZ0u6TpJqxRVmsPluT8WXSS1wTwXSbnIioqPuC9J+sI5tzX+vJ2iv6kVwrWSFkqaY2ZfSnpB0bMLOeeeVfSYvBS3eSmtE+fcXxVd2DReUXH1iqJqWYqu8zjboquvb/ccfrmiv4l+Jul1SX9S9HfQb2Rm15nZsylj2lTpsdwgaYuLdn/UJUHO9VgnSW8q+v4/KGmEc25Wxu3M9djO5nrsfEXPhldKOkHSD5xzde1POSHP9RMkvWtmG+NxPq5ok0MF5nosi7l+k6KXf/hU0keKVsDGZtN3viy+wAUeZraLpAWSDnbObavp8QDFwlxHXcFcDx+FCQAACAav/AoAAIJBYQIAAIJBYQIAAIKx09cxMTMuQEGNc84V6vUHUjHXEYLqmOsS8x1hSJvvrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgNKjpAQAAUBc1b97cm7dv377KfZeVlXnzX/3qV978/fff9+affvqpN1+wYEF+A8sCKyYAACAYFCYAACAYFCYAACAYFCYAACAYFCYAACAYdWpXTps2bbz5I4884s3ffPPNRHbPPfd42y5evDjvcdWkZs2aefNjjz3Wm8+cOdObb9u2rWBjAoBSdcopp3jz0047LZH16dPH27Zz585VHkfabpoOHTp480aNGuXUf/369XMeU7ZYMQEAAMGgMAEAAMGgMAEAAMGgMAEAAMGgMAEAAMGolbty0t5/4IMPPvDmaTtTvvjii0RWqrtvJP/9nDdvnrdt69atvfmhhx7qzRcuXJj/wFDj9thjj0R28803e9t269bNm/ft29ebs2MLpaBTp07e/LLLLvPmF198sTdv0qSJNzez/AaWpy5dulTr+QqJFRMAABAMChMAABAMChMAABAMChMAABCMkr74tVWrVt586tSp3rxFixbefMKECd788ssvz29ggRo5cmQi+/a3v+1te8kll3hzLnItbYMHD/bmY8eOTWTt2rXLqW/fBbSS9Pe//z2nfoCasO+++3rzK664oppHkruPP/44kaVt9igFrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBgmHMu/Uaz9BsDcOKJJ3rzZ599Nqd+2rZt681XrVqV85hCcOCBB3rz9957L5E98cQT3rZDhw715l999VXe48qXc67or+Uc+lzPVdoOg3feecebt2zZMpHt7GeDT9puuGHDhnnzNWvW5NR/XVAdc10q3fmethMzbefMG2+84c1nzpyZyHr37u1tO2PGDG++ceNGb960aVNvPmvWrET2/vvve9v+5S9/8eZp/383b96c9fhCkjbfWTEBAADBoDABAADBoDABAADBoDABAADBoDABAADBKJn3ymnTpk0iO+uss3Lq46KLLvLmtW33zQsvvJB1H2m7cmpi9w0K5+qrr/bmae8XVQjnnHOON+/fv783970/zx133OFtu3Xr1vwHhpKTy84WSTrkkEO8+Zlnnpn1OefMmePNe/bs6c0XL17szdu3b+/Nly1blsjKy8uzG1wdw4oJAAAIBoUJAAAIBoUJAAAIBoUJAAAIBoUJAAAIRsm8V87kyZMT2XnnnedtO2/ePG9+3HHHefNSeE8Bn0svvdSbT5gwwZtPmjQpkV144YWFHFJR8F456Tp06ODN3333XW++2267eXPf+yh98cUX3rZ9+/bNcnQ7t3LlykTWo0cPb9sVK1YU5Jyhq4vvlbPLLrskskcffdTb9tRTT/Xmv/vd77z5zTff7M03bdqU5ehQTLxXDgAACB6FCQAACAaFCQAACAaFCQAACAaFCQAACEbJvFeOb/dQ2vsMLF++3JuXwvttNGnSJJFdd9113rY///nPvXnaTqtS2IGD3HTv3t2b77777t78tdde8+a+HWuNGzf2tv23f/s3b542Tzt16uTN27Ztm8ieeuopb9uTTjrJm69Zs8abIzxpO8J+/etfJ7K03TerV6/25n/4wx+8ObtvShMrJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBglc/FrLk455RRvPmvWLG++bt06bz5x4sRCDSkh7eXx+/Tpk8h69+6dU9/Tpk3LZ0goQY0aNfLmaRdAjx8/Puu+t2zZ4s0feOABbz5w4EBv3rFjx6zPmXaxYilcuI6dO+OMM7z5iBEjEtmSJUu8bY855hhvvn79+rzHhfCwYgIAAIJBYQIAAIJBYQIAAIJBYQIAAIJBYQIAAIJRMrtybrvttkR2/PHHe9vuvffe3vzYY4/15mbmzU877bQsR5e7tHOm7abw+eyzz7x52kuDo/ZJe3n4NGk71p588skqj6VXr15V7mPOnDnefMOGDVXuGzXrqKOOyrrtO++8482XLVtWqOEgYKyYAACAYFCYAACAYFCYAACAYFCYAACAYFCYAACAYNjOdoGYWfZbRGpA8+bNvXn37t29ef/+/b358OHDvfnKlSsT2YMPPpjd4L7B5MmTvfmCBQuy7uPhhx/25kOGDMlrTKFyzvm3MBVQ6HM9zY9+9CNvPmXKFG/+3nvvefNBgwYlsoMOOsjb9swzz/Tmae+V8+WXX3pz3//fNWvWeNum7aj78MMPvXmpqo65LtXMfPf9PJWkli1bJrJ//OMf3ra///3vvflTTz3lzefPn5/d4FAj0uY7KyYAACAYFCYAACAYFCYAACAYFCYAACAYFCYAACAYJb0rp5R17NjRmy9cuDCRpV1Z3q9fP2++atWqvMcVInblpGvRooU3980jSWrWrJk39713Uy7v2yRJL7zwgje/7LLLvPn06dMT2f777+9te++993rzSy+9NMvRlYbavCsnbT6Vl5dXue+0Pu6++25v7ntPpvbt23vbpv1f+uCDD7IcXeTAAw9MZG+99Za3bV15TyB25QAAgOBRmAAAgGBQmAAAgGBQmAAAgGBQmAAAgGCwK6eGTJo0yZuff/75iSztPX6ef/75Qg4pWOzKyV3fvn29+bRp07y5b7dO2s+GO+64w5tfe+213nzLli3e/He/+10iGzFihLdtWVmZN0+7n4sWLfLmoavNu3JuueUWb37llVdW80jCkbaDcvbs2d7c955WpYxdOQAAIHgUJgAAIBgUJgAAIBgUJgAAIBhc/FpkAwcO9OZTp0715l999VUiO/74471t//d//zf/gZUQLn4tnLSLRc8999xEtm7dOm/b3/zmN958w4YNOY2lSZMmiexPf/qTt+1pp53mzR9++GFvPmTIkJzGEorafPFr/fr1vXmPHj0SWdo8aNCggTdv166dN69XrzSfe6f9Xh41apQ3HzNmTBFHUzxc/AoAAIJHYQIAAIJBYQIAAIJBYQIAAIJBYQIAAILhv8QZBXPSSSfl1H769OmJrK7svkHxvfDCCznlxbR58+ZElrZbLW1XTtqOtRYtWiSyNWvW5DA6FNqOHTu8+dy5cxNZly5dcur7hBNO8OYNGzb05r7dLYcddlhO5ywmM//mrEMPPbSaR1IzWDEBAADBoDABAADBoDABAADBoDABAADBoDABAADBYFdOkaXtytm4caM3/4//+I9iDgcI2iOPPOLN03blnHPOOd582LBhiWz06NH5DwxBe/HFF3Nq371790SWtitn+/bt3vyBBx7w5vfee683/+Uvf5nIfO9RBVZMAABAQChMAABAMChMAABAMChMAABAMChMAABAMMw5l36jWfqN+JpLL73Um0+YMMGbr1y50pu3bdu2YGOqLZxz/jeOKCDmeth8uygk6Y033vDmjRs3TmTf/e53vW0//fTTvMdVaNUx1yXme8+ePRPZ22+/XZC+X375ZW/ep0+fRJb2njhp0n6fXH755Tn1E4q0+c6KCQAACAaFCQAACAaFCQAACAaFCQAACAYXvxbI/PnzvflBBx3kzSdNmuTNL7rookS2++67e9s2b97cmy9ZssSblyoufkWaq666ypvfcsstiezxxx/3tj3//PO9+ebNm/MfWJ64+LV6NGnSJJHdf//93rY/+tGPijaOHTt2ePNnnnnGm5933nnePO0tTkLHxa8AACB4FCYAACAYFCYAACAYFCYAACAYFCYAACAY7MopkFx35dx3333e/JVXXklkv/rVr7xtP/jgA28+ZMgQb16q2JWDNK1bt/bmvpeq79y5s7dt2svdv/vuu3mPK1/syqk5e+65pzf/r//6L2/eq1cvb96mTRtvvnjx4kQ2efJkb9tRo0Z589qGXTkAACB4FCYAACAYFCYAACAYFCYAACAYFCYAACAY7MopkFx35Zj5L773fT/SdvDcdNNN3nzp0qXevFSxKwe5at++fSLz7YqQpClTpnjzwYMHF3JIWWFXTulIe4+l3r17e/Pf/va3iWzlypUFHVOpYVcOAAAIHoUJAAAIBoUJAAAIBoUJAAAIBoUJAAAIBrtyCuToo4/25qNHj/bmr776qjefOHFiIlu7dq237datW7McXWljVw4KYdasWd78yCOP9OZHHHGEN//www8LNqbK2JWDuoRdOQAAIHgUJgAAIBgUJgAAIBgUJgAAIBgUJgAAIBjsykHw2JWDQthjjz28+YIFC7z5FVdc4c2ffvrpgo2pMnbloC5hVw4AAAgehQkAAAgGhQkAAAgGhQkAAAgGF78ieFz8irqCi19Rl3DxKwAACB6FCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACAaFCQAACMZO3ysHAACgOrFiAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgkFhAgAAgvH/Aep1nvDG15GFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and test the model for the specified number of epochs\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\ttrain(model, device, train_loader, criterion, optimizer, epoch) # Train the model\n",
    "\ttest(model, device, test_loader, criterion) # Test the model\n",
    "\n",
    "# Visualize some sample images and predictions\n",
    "samples, labels = next(iter(test_loader)) # Get a batch of test data\n",
    "samples = samples.to(device) # Move the samples to the device\n",
    "outputs = model(samples) # Get the output logits from the model\n",
    "_, preds = torch.max(outputs, 1) # Get the predicted classes from the output logits\n",
    "samples = samples.cpu().numpy() # Move the samples back to CPU and convert to numpy array\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8)) # Create a 3x3 grid of subplots\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "\tax.imshow(samples[i].squeeze(), cmap='gray') # Plot the image\n",
    "\tax.set_title(f'Label: {labels[i]}, Prediction: {preds[i]}') # Set the title\n",
    "\tax.axis('off') # Hide the axes\n",
    "plt.tight_layout() # Adjust the spacing\n",
    "plt.show() # Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164876f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
